# ============================================================================
# InsightsLM Backend - Complete Dependency Lock File
# Generated from: pip freeze
# Date: November 7, 2025
# Python: 3.12.3
# Platform: WSL2 Ubuntu 24.04
# GPU: NVIDIA GeForce GTX 1660 SUPER (6GB)
# Performance: 19x real-time transcription (52s for 16min audio)
# ============================================================================
#
# This file contains EXACT versions of ALL packages in the working environment.
# Use this for:
#   - Exact reproduction of production environment
#   - CI/CD pipelines
#   - Debugging version-specific issues
#
# Install with:
#   pip install -r requirements-lock.txt
#
# ============================================================================

annotated-doc==0.0.3
annotated-types==0.7.0
anthropic==0.72.0
anyio==4.11.0
appdirs==1.4.4
attrs==25.4.0
av==16.0.1
backoff==2.2.1
bcrypt==5.0.0
build==1.3.0
cachetools==6.2.1
certifi==2025.10.5
charset-normalizer==3.4.4
chromadb==1.3.4
click==8.1.8
coloredlogs==15.0.1
ctranslate2==4.6.0
distro==1.9.0
docstring_parser==0.17.0
durationpy==0.10
environs==14.5.0
fastapi==0.121.0
fastapi_cors==0.0.6
faster-whisper==1.2.1
ffmpeg-python==0.2.0
filelock==3.20.0
flatbuffers==25.9.23
fsspec==2025.10.0
future==1.0.0
google-ai-generativelanguage==0.6.15
google-api-core==2.28.1
google-api-python-client==2.187.0
google-auth==2.43.0
google-auth-httplib2==0.2.1
google-generativeai==0.8.5
googleapis-common-protos==1.72.0
greenlet==3.2.4
grpcio==1.76.0
grpcio-status==1.71.2
gTTS==2.5.4
h11==0.16.0
hf-xet==1.2.0
httpcore==1.0.9
httplib2==0.31.0
httptools==0.7.1
httpx==0.28.1
huggingface-hub==0.36.0
humanfriendly==10.0
idna==3.11
importlib_metadata==8.7.0
importlib_resources==6.5.2
Jinja2==3.1.6
jiter==0.11.1
joblib==1.5.2
jsonschema==4.25.1
jsonschema-specifications==2025.9.1
kubernetes==34.1.0
llvmlite==0.45.1
markdown-it-py==4.0.0
MarkupSafe==3.0.3
marshmallow==4.1.0
mdurl==0.1.2
mmh3==5.2.0
more-itertools==10.8.0
mpmath==1.3.0
networkx==3.5
numba==0.62.1
numpy==2.3.4
nvidia-cublas-cu12==12.8.4.1
nvidia-cuda-cupti-cu12==12.8.90
nvidia-cuda-nvrtc-cu12==12.8.93
nvidia-cuda-runtime-cu12==12.8.90
nvidia-cudnn-cu12==9.10.2.21
nvidia-cufft-cu12==11.3.3.83
nvidia-cufile-cu12==1.13.1.3
nvidia-curand-cu12==10.3.9.90
nvidia-cusolver-cu12==11.7.3.90
nvidia-cusparse-cu12==12.5.8.93
nvidia-cusparselt-cu12==0.7.1
nvidia-nccl-cu12==2.27.5
nvidia-nvjitlink-cu12==12.8.93
nvidia-nvshmem-cu12==3.3.20
nvidia-nvtx-cu12==12.8.90
oauthlib==3.3.1
ollama==0.6.0
onnxruntime==1.23.2
openai==2.7.1
openai-whisper==20250625
opentelemetry-api==1.38.0
opentelemetry-exporter-otlp-proto-common==1.38.0
opentelemetry-exporter-otlp-proto-grpc==1.38.0
opentelemetry-proto==1.38.0
opentelemetry-sdk==1.38.0
opentelemetry-semantic-conventions==0.59b0
orjson==3.11.4
overrides==7.7.0
packaging==25.0
pillow==12.0.0
posthog==5.4.0
proto-plus==1.26.1
protobuf==5.29.5
py-cpuinfo==9.0.0
pyasn1==0.6.1
pyasn1_modules==0.4.2
pybase64==1.4.2
pycryptodome==3.23.0
pydantic==2.12.4
pydantic_core==2.41.5
Pygments==2.19.2
pyparsing==3.2.5
PyPika==0.48.9
pyproject_hooks==1.2.0
python-dateutil==2.9.0.post0
python-dotenv==1.2.1
python-multipart==0.0.20
PyYAML==6.0.3
referencing==0.37.0
regex==2025.11.3
requests==2.32.5
requests-oauthlib==2.0.0
rich==14.2.0
rpds-py==0.28.0
rsa==4.9.1
safetensors==0.6.2
scikit-learn==1.7.2
scipy==1.16.3
sentence-transformers==5.1.2
setuptools==80.9.0
shellingham==1.5.4
six==1.17.0
sniffio==1.3.1
SQLAlchemy==2.0.44
starlette==0.49.3
sympy==1.14.0
tenacity==9.1.2
threadpoolctl==3.6.0
tiktoken==0.12.0
tokenizers==0.22.1
torch==2.9.0
tqdm==4.67.1
transformers==4.57.1
triton==3.5.0
typer==0.20.0
typing-inspection==0.4.2
typing_extensions==4.15.0
uritemplate==4.2.0
urllib3==2.3.0
uvicorn==0.38.0
uvloop==0.22.1
watchfiles==1.1.1
websocket-client==1.9.0
websockets==15.0.1
yt-dlp==2025.10.22
zipp==3.23.0

# ============================================================================
# NOTES
# ============================================================================
#
# 1. openai-whisper==20250625 is still installed but NOT used
#    - The application uses faster-whisper instead
#    - Safe to uninstall: pip uninstall openai-whisper
#    - Kept in lock file to match current environment exactly
#
# 2. CUDA Toolkit packages (nvidia-*) are critical for GPU acceleration
#    - Total: 15 nvidia packages
#    - Must have NVIDIA driver 535+ installed on host system
#    - WSL2 uses Windows host GPU drivers
#
# 3. LD_LIBRARY_PATH must be set for cuDNN:
#    export LD_LIBRARY_PATH="$PWD/venv/lib/python3.12/site-packages/nvidia/cudnn/lib:$LD_LIBRARY_PATH"
#    (Add to ~/.bashrc for persistence)
#
# 4. System Requirements:
#    - Ubuntu 24.04 (or compatible)
#    - Python 3.12.3
#    - NVIDIA GPU with CUDA support (optional, falls back to CPU)
#    - 8GB+ RAM recommended
#    - 20GB+ disk space for models
#
# ============================================================================
